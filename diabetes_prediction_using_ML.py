# -*- coding: utf-8 -*-
"""diabetes prediction using python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GzXnQf6v1WSA8FKHar8J8UiC5S03Mlk9
"""

# importing dependencies
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

# data loading into the kernel
diabetes_dataset = pd.read_csv('diabetes.csv')
diabetes_dataset.head()

"""1 = DAIBETIC

0 = NOT DIABETIC

"""

diabetes_dataset.shape

# getting the statistical measures of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()
# EDA Visualizations
sns.countplot(data=df, x='Outcome')
plt.title("Class Distribution"); plt.show()
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation"); plt.show()

diabetes_dataset.groupby('Outcome').mean()

# separating input and outcome variables
X = diabetes_dataset.drop(columns= 'Outcome', axis = 1) # axis = 1 implies dropping the coloumn
Y = diabetes_dataset['Outcome']

X

Y

# standardising the data
scaler = StandardScaler()

scaler.fit(X)

standardized_data = scaler.transform(X)

standardized_data

X = standardized_data
Y = diabetes_dataset['Outcome']

# splitting data into train and test data
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify = Y, random_state = 2)



# training the model
classifier = svm.SVC(kernel = 'linear')

# training the SVC classifier
classifier.fit(X_train, Y_train)

# Evaluation on test data
y_pred = best_svm.predict(X_test)
print("\nClassification Report:\n", classification_report(Y_test, y_pred))
conf_mat = confusion_matrix(Y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d')
plt.title("Confusion Matrix"); plt.show()

# evaluating our model by finding accuracy score
# on training data
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print(training_data_accuracy)

# on test data
X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print(test_data_accuracy)

# Hyperparameter tuning for SVM
param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
grid = GridSearchCV(SVC(probability=True), param_grid, cv=5)
grid.fit(X_train, Y_train)
print("Best SVM Params:", grid.best_params_)
best_svm = grid.best_estimator_

# Cross-validation
cv_scores = cross_val_score(best_svm, X_scaled, Y, cv=5)
print(f"SVM Cross-Validation Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

# making a prediction system
input_data = (4, 110,92,0,0,37.6,0.191,30)

# changing the input data into a numpy array
input_data_as_nparray = np.asarray(input_data)

# reshaping the data
input_data_reshaped = input_data_as_nparray.reshape(1,-1)

# standardise the input data
std_data = scaler.transform(input_data_reshaped)
print(std_data)

prediction = classifier.predict(std_data)
print(prediction)

if(prediction[0] == 0):
    print('The person is not diabetic')
else:
    print('The person is diabetic')

"""WE NOW COMPARE SOME OF THE OTHER ML CLASSIFIER MODELS AND SEE WHICH ONE WORKS THE BEST FOR US"""

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, stratify=Y, random_state=42)

# Model comparison
models = {
    'SVM': SVC(probability=True, kernel='linear'),
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier()
}
results = {}
for name, model in models.items():
    model.fit(X_train, Y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(Y_test, preds)
    results[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")

# Visualize model comparison
sns.barplot(x=list(results.keys()), y=list(results.values()))
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy"); plt.ylim(0.7, 1.0)
plt.xticks(rotation=20)
plt.show()

"""WE CAN SEE THAT RANDOM FOREST REGRESSOR WORKS THE BEST IN OUR CASE"""

# ROC Curve
y_probs = best_svm.predict_proba(X_test)[:,1]
fpr, tpr, _ = roc_curve(Y_test, y_probs)
plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(Y_test, y_probs):.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
plt.title("ROC Curve"); plt.legend(); plt.show()

# Predictive system using the trained Random Forest model

# Sample input data (you can replace these values)
input_data = (4, 110, 92, 0, 0, 37.6, 0.191, 30)

# Convert to numpy array and reshape
input_array = np.asarray(input_data).reshape(1, -1)

# Standardize input using previously fitted scaler
input_scaled = scaler.transform(input_array)

# Predict using trained Random Forest model
prediction = models['Random Forest'].predict(input_scaled)
probability = models['Random Forest'].predict_proba(input_scaled)[0][1]

# Output result
if prediction[0] == 1:
    print(f"The person is DIABETIC (Confidence: {probability:.2f})")
else:
    print(f"The person is NOT DIABETIC (Confidence: {1 - probability:.2f})")